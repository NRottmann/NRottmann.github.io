[{"authors":["admin"],"categories":null,"content":"Mobile Robots. Sensors. Machine Learning. Dancing.\n","date":1630454400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1630454400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://nrottmann.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Mobile Robots. Sensors. Machine Learning. Dancing.","tags":null,"title":"Nils Rottmann","type":"authors"},{"authors":["Nils Rottmann","Robin Denz","Ralf Bruder","Elmar Rueckert"],"categories":null,"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"60fad4732cd5fe6510dd9497b1539f3a","permalink":"https://nrottmann.github.io/publication/ecmr2021/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/publication/ecmr2021/","section":"publication","summary":"Domestic robots, such as vacuum cleaners or lawn mowers, are mostly based on a low-cost design to make them affordable for the consumer. This often results in such robots being equipped with only simple sensors, such as in-/outside area detectors for lawn mowers. Intelligent navigation and planning strategies, however, usually require additional sensors like LiDAR sensors, cameras or time of flight sensors. Thus, there is a lack of intelligent approaches for the complete coverage of the workspace under consideration of only minimal sensing capabilities. In this work, we propose a probabilistic planning method for low-cost robots with limited sensing capabilities to completely cover an enclosed environment. Our planning approach thereby utilizes Monte Carlo Localization for estimating coverage probabilities based on the particle distribution. These coverage probabilities are stored in a grid map on the basis of which an intelligent path planning approach determines the next locations to be visited. We demonstrate our approach in different simulation scenarios for a realistic autonomous lawn mower with only in-/outside area detection capabilities. As comparison benchmark we use the common random walk mowing pattern.","tags":["Mobile Robotics","Planning","Navigation"],"title":"Loop Closure Detection in Closed Environments","type":"publication"},{"authors":null,"categories":null,"content":"","date":1621641600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621641600,"objectID":"1d1361d1089fa62abef417a592666d4e","permalink":"https://nrottmann.github.io/project/ros_mobile/","publishdate":"2021-05-22T00:00:00Z","relpermalink":"/project/ros_mobile/","section":"project","summary":"An Android application designed for dynamic control and visualization of mobile robotic system operated by the ROS.","tags":["Mobile Robotics","ROS","Mobile Devices"],"title":"ROS-Mobile","type":"project"},{"authors":["Leander Busch"],"categories":null,"content":" Abstract The Segway Loomo is a self-balancing segway robot, which is constantly balanced by an internal control system. A local path planning strategy was developed in advance for this robot. For local path planning, a motion model of the robot is needed to determine the effect of velocity commands on the robot’s pose. In the implemented local path planner, a simple motion model of the robot is used, which does not model the effect of the segway robot’s internal control on its motion. In this work, it was investigated whether a more accurate motion model for the Segway Loomo robot can be learned by using artificial neural networks to improve the local path planning for this robot. For this purpose, different architectures of feedforward networks were tested. The neural networks were trained and evaluated using recorded motion data of the segway robot. The best learned model was validated by using a standard differential drive motion model as a reference. For the validation of the learned model, the accuracy of both motion models was examined on the recorded motion data. On average, the learned model is 59.48 % more accurate in determining the position of the robot at the next time step and 24.61 % more accurate in determining the new orientation of the robot than the differential drive motion model.\n","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"3103234f9c8c97da35694e32e6ec0a32","permalink":"https://nrottmann.github.io/thesis/leanderbusch/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/thesis/leanderbusch/","section":"thesis","summary":"Abstract The Segway Loomo is a self-balancing segway robot, which is constantly balanced by an internal control system. A local path planning strategy was developed in advance for this robot. For local path planning, a motion model of the robot is needed to determine the effect of velocity commands on the robot’s pose. In the implemented local path planner, a simple motion model of the robot is used, which does not model the effect of the segway robot’s internal control on its motion.","tags":["Mobile Robotics","Planning","Machine Learning"],"title":"Learning Motion Models for Local Path Planning Strategies","type":"thesis"},{"authors":["Mehmet Ege Cansev","Honghu Xue","Nils Rottmann","Adna Bliek","Luke E. Miller","Elmar Rueckert","Philipp Beckerle"],"categories":null,"content":"","date":1612051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612051200,"objectID":"0c25b1656630ffc7a58758700be5c720","permalink":"https://nrottmann.github.io/publication/aisjournal2021/","publishdate":"2021-01-22T00:00:00Z","relpermalink":"/publication/aisjournal2021/","section":"publication","summary":"Generalizing the operation of robots in dynamical environments regardless of the task complexity is one of the ultimate goals of robotics researchers. Learning from demonstration approaches supported by transfer learning and user feedback offer a remarkable solution to achieve generalization. The main idea behind such approaches is teaching robots new skills with human instructors and training parametric models with data from demonstrations to achieve and update the desired skills under changing conditions. The applications of skill transfer with reinforcement learning algorithms and the effect of user experience on learning from demonstration approaches are reviewed in this paper. This review outlines the importance of considering and evaluating user experience during human-robot interaction and, especially, robot teaching. A detailed view on the relations between robot learning and user experience is provided and approaches for future improvements are derived. Finally, adaptive autonomy sharing between the robot and the user during teaching is presented as a promising approach to enhance the interaction by exploiting user feedback. In the long run, interactive and user-centered human-robot skill transfer is expected to reduce cognitive and physical load of the user. Discussion on future research questions aiming to improve learning process and semi-autonomous behavior concludes the review.","tags":["Reinforcement Learning","Human-Robot Interaction"],"title":"Interactive Human-Robot Skill Transfer: A Review of Learning Methods and User Experience","type":"publication"},{"authors":["Nils Rottmann","Ralf Bruder","Achim Schweikard","Elmar Rueckert"],"categories":null,"content":"","date":1604102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604102400,"objectID":"ac993ff2103935d72c8e1f96ed35fbc5","permalink":"https://nrottmann.github.io/publication/sensorjournal2020/","publishdate":"2020-10-22T00:00:00Z","relpermalink":"/publication/sensorjournal2020/","section":"publication","summary":"Detecting cost-effectively and accurately the working area for autonomous lawn mowers is key for widespread automation of garden care. At present this is realized by means of perimeter wire, which leads to high setup and maintenance costs. Here, we propose an active low-cost sensor approach for detecting chlorophyll ﬂuorescence response. Our novel and innovative sensing concept allows for a robust working area detection. The classiﬁcation is thereby based on the averaging of multiple measurements using LED pulses and sensed ﬂuorescence responses. By selecting only low-cost consumer components for the sensor design, we allow for high-volume production under low-cost aspects.\nWe evaluated our novel sensor system by analyzing theoretically the signal path. Among other we investigated sampling frequencies, sensed surface areas and environmental inﬂuences. In real world experiments, we evaluated the performance of our sensor in an exemplary garden and on collected grass samples. Our theoretical and practical evaluations show that the sensor classiﬁcation result is robust under different environmental conditions, such as changes in lawn quality.","tags":["Sensors","Mobile Robotics"],"title":"A novel Chlorophyll Fluorescence based approach for Mowing Area Classiﬁcation","type":"publication"},{"authors":[],"categories":null,"content":"","date":1603612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603612800,"objectID":"2af3f97278047d3ac207013a3e71e0ee","permalink":"https://nrottmann.github.io/talk/sensors2020/","publishdate":"2020-09-15T00:00:00Z","relpermalink":"/talk/sensors2020/","section":"talk","summary":"A talk about a low-cost mowing area detector","tags":["Sensors","Optimization","Mobile Robotics"],"title":"Exploiting Chlorophyll Fluorescense for building robust low-cost Mowing Area Detectors","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603612800,"objectID":"b61d169f12c1f3375405e6b9be4539a6","permalink":"https://nrottmann.github.io/talk/iros2020/","publishdate":"2020-09-15T00:00:00Z","relpermalink":"/talk/iros2020/","section":"talk","summary":"A talk about how hierarchical acquisition functions can improve the performance of Bayesian Optimization on complex problems.","tags":["Reinforcement Learning","Optimization","Humanoids"],"title":"Learning Hierarchical Acquisition Functions for Bayesian Optimization","type":"talk"},{"authors":[],"categories":null,"content":"","date":1603612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603612800,"objectID":"b99565e0f7f41e9b2e6f16e7cc3f25f5","permalink":"https://nrottmann.github.io/talk/irosws2020/","publishdate":"2020-09-15T00:00:00Z","relpermalink":"/talk/irosws2020/","section":"talk","summary":"A workshop talk about how meta-parameters, required for most mapping algorithms, can be learned.","tags":["Mobile Robotics","Optimization","Reinforcement Learning"],"title":"Parameter Optimization for Loop Closure Detection in Closed Environments","type":"talk"},{"authors":["Nils Rottmann","Ralf Bruder","Achim Schweikard","Elmar Rueckert"],"categories":null,"content":"","date":1603584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603584000,"objectID":"d3e44aea0a053f1c7ddfa304fe1c0122","permalink":"https://nrottmann.github.io/publication/sensorconf2020/","publishdate":"2020-09-02T00:00:00Z","relpermalink":"/publication/sensorconf2020/","section":"publication","summary":"Detecting cost-effectively and accurately the working area for autonomous lawn mowers is key for widespread automation of garden care. Therefore, we propose an active low-cost sensor approach for detecting fluorescence response. The area to be detected is illuminated by an LED and the chlorophyll fluorescence response is observed by a phototransistor. The signal from the phototransistor is further processed by a transimpedance amplifier, an amplifier and a band pass filter and forwarded to a microprocessor. By choosing only low-cost consumer products for construction, high-volume lowest cost sensors can be built. We demonstrate the feasibility of our low-cost approach by evaluating the sensor mounted on an autonomous lawn mower in a garden environment.","tags":["Sensors"],"title":"Exploiting Chlorophyll Fluorescense for building robust low-cost Mowing Area Detectors","type":"publication"},{"authors":["Nils Rottmann","Tjasa Kunavar","Jan Babic","Jan Peters","Elmar Rueckert"],"categories":null,"content":"","date":1603584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603584000,"objectID":"3dfaefc104da06960cbd54eb7a79d89d","permalink":"https://nrottmann.github.io/publication/iros2020/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/publication/iros2020/","section":"publication","summary":"Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. In order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process. The features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. The method outperforms standard optimization techniques, such as Bayesian Optimization, in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. Further, we show that our method performs similar to humans for learning the postural balancing task by comparing our simulation results with real human data.","tags":["Reinforcement Learning","Optimization","Humanoids"],"title":"Learning Hierarchical Acquisition Functions for Bayesian Optimization","type":"publication"},{"authors":["Nils Rottmann","Ralf Bruder","Honghu Xue","Achim Schweikard","Elmar Rueckert"],"categories":null,"content":"","date":1603584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603584000,"objectID":"557edc72fa610b949ed9bff874898c40","permalink":"https://nrottmann.github.io/publication/iros2020ws/","publishdate":"2020-09-02T00:00:00Z","relpermalink":"/publication/iros2020ws/","section":"publication","summary":"Tuning parameters is crucial for the performance of localization and mapping algorithms. In general, the tuning of the parameters requires expert knowledge and is sensitive to information about the structure of the environment. In order to design truly autonomous systems the robot has to learn the parameters automatically. Therefore, we propose a parameter optimization approach for loop closure detection in closed environments which requires neither any prior information, e.g. robot model parameters, nor expert knowledge. It relies on several path traversals along the boundary line of the closed environment. We demonstrate the performance of our method in challenging real world scenarios with limited sensing capabilities. These scenarios are exemplary for a wide range of practical applications including lawn mowers and household robots.","tags":["Mobile Robotics","Mapping","Reinforcement Learning","Optimization"],"title":"Parameter Optimization for Loop Closure Detection in Closed Environments","type":"publication"},{"authors":null,"categories":null,"content":"","date":1603324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603324800,"objectID":"28ff79b20324e6b0045b5c748e13d846","permalink":"https://nrottmann.github.io/project/a_drz/","publishdate":"2020-10-22T00:00:00Z","relpermalink":"/project/a_drz/","section":"project","summary":"Aufbau des Deutschen Rettungsrobotik-Zentrums (A-DRZ)","tags":["Mobile Robotics","Navigation","Planning","ROS","Sensors","Localization","SLAM"],"title":"A-DRZ (expired)","type":"project"},{"authors":[],"categories":null,"content":"","date":1602489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602489600,"objectID":"876b8ef8e8cb4154019320a4ccab256b","permalink":"https://nrottmann.github.io/talk/autumnschool2020/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/talk/autumnschool2020/","section":"talk","summary":"Navigation, Path Planning and ROS for Mobile Robotos","tags":["Mobile Robotics","SLAM","Navigation","Localization","ROS"],"title":"Autumn School","type":"talk"},{"authors":["Jan-Philip Klose"],"categories":null,"content":" Abstract Upon illumination of a sufficient amount of light, the chlorophyll molecules of a plant start to emit photons in the far red region of the light spectrum. This phenomenon is also known as chlorophyll fluorescence. In this thesis a classi- fier is built that serves as a benchmark for plant classification via chlorophyll a fluorescence. A data set of 2500 samples was acquired by illuminating a total of 500 leaves gathered from five different plants with seven LEDs. To achieve an optimal model, a convolutional neural network (CNN) was designed and trained on complete fluorescence spectra. The network achieved an average accuracy of 95,7% on classifying five plants. Furthermore, the networks ac- curacy on a smaller set of LEDs was tested. In the end, a low cost approach was trained and evaluated, reaching an accuracy of 68%. This approach uses simulated phototransistor data instead of full spectra acquired with a spec- trometer.\n","date":1598486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598486400,"objectID":"da17c108b521226c685dcd7f4217b50e","permalink":"https://nrottmann.github.io/thesis/janphilipklose/","publishdate":"2020-08-27T00:00:00Z","relpermalink":"/thesis/janphilipklose/","section":"thesis","summary":"Abstract Upon illumination of a sufficient amount of light, the chlorophyll molecules of a plant start to emit photons in the far red region of the light spectrum. This phenomenon is also known as chlorophyll fluorescence. In this thesis a classi- fier is built that serves as a benchmark for plant classification via chlorophyll a fluorescence. A data set of 2500 samples was acquired by illuminating a total of 500 leaves gathered from five different plants with seven LEDs.","tags":["Sensors","Optimization","Machine Learning"],"title":"Plant Classification based on Chlorophyll Detection for autonomous Gardening","type":"thesis"},{"authors":["Honghu Xue","Sven Boettger","Nils Rottmann","Harit Pandya","Ralf Bruder","Gerhard Neumann","Elmar Rueckert"],"categories":null,"content":"","date":1593475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593475200,"objectID":"c672e007d2aec590fcca31901b49a586","permalink":"https://nrottmann.github.io/publication/aspai2020/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/publication/aspai2020/","section":"publication","summary":"Gradient-free reinforcement learning algorithms often fail to scale to high dimensions and require a large number of rollouts. In this paper, we propose learning a predictor model that allows simulated rollouts in a rank-based black-box optimizer Covariance Matrix Adaptation Evolutional Strategy (CMA-ES) to achieve higher sample-efficiency. We validated the performance of our new approach on different benchmark functions where our algorithm shows a faster convergence compared to the standard CMA-ES. As a next step, we will evaluate our new algorithm in a robot cup flipping task","tags":["Reinforcement Learning","Optimization","Dynamic Movement Primitives"],"title":"Sample-Efficient Covariance Matrix Adaptation Evolutional Strategy via Simulated Rollouts in Neural Networks","type":"publication"},{"authors":["Nils Rottmann"],"categories":[],"content":"I had the opportunity to attend the MLSS 2020. I got a lot of interesting insights into the different fields of Machine Learning such as Causality, Fairness, Reinforcement Learning and many more. Most of the lectures hold during the summer school are available at YouTube. For further information, just visit the website.\n","date":1593460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593460800,"objectID":"5e1d7efb311f6e26f9368e3036cf7738","permalink":"https://nrottmann.github.io/post/mlss2020/","publishdate":"2020-06-29T20:00:00Z","relpermalink":"/post/mlss2020/","section":"post","summary":"The Machine Learning Summer School 2020 in Tuebingen, this time as a virtual event.","tags":[],"title":"MLSS 2020, Tuebingen, virtual","type":"post"},{"authors":["Michael Werner"],"categories":null,"content":" Abstract Bayesian Optimization is a powerful method to optimize black-box derivative-free functions, with high evaluation costs. For instance, applications can be found in the context of robotics, animation design or molecular design. However, Bayesian Optimization is not able to scale into higher dimensions, equivalent to optimizing more than 20 parameters. This thesis introduces HIBO, a new hierarchical algorithm in the context of high dimensional Bayesian Optimization. The algorithm uses an automatic feature generation. The features are used to condition the parameters, to enable faster optimization. The performance of HIBO is compared to existing high dimensional extensions of Bayesian Optimization on three common benchmark functions. Additionally, an air hockey simulation is used to examine the capability in a task-oriented setting. The conducted experiments show that HIBO performs similar to the basic Bayesian Optimization algorithm, independent from the dimensionality of the given problem. Hence, the proposed HIBO algorithm does not scale Bayesian Optimization to higher dimensions.\n","date":1573689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573689600,"objectID":"32e426adce54072ff1f54e82be25b0c7","permalink":"https://nrottmann.github.io/thesis/michaelwerner/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/thesis/michaelwerner/","section":"thesis","summary":"Abstract Bayesian Optimization is a powerful method to optimize black-box derivative-free functions, with high evaluation costs. For instance, applications can be found in the context of robotics, animation design or molecular design. However, Bayesian Optimization is not able to scale into higher dimensions, equivalent to optimizing more than 20 parameters. This thesis introduces HIBO, a new hierarchical algorithm in the context of high dimensional Bayesian Optimization. The algorithm uses an automatic feature generation.","tags":["Reinforcement Learning","Optimization","Humanoid Robotics"],"title":"HIBO: Hierarchical Acquisition Functions for Bayesian Optimization","type":"thesis"},{"authors":["Nico Studt"],"categories":null,"content":" Abstract The focus of this work is on extending the functionality of the robot platform Loomo. Using cartography and navigation methods, the basis for an autonomous system is created. In addition, the recognition and storage of AR markers simplifies human-robot interaction by enabling targeted navigation to specific locations. The implementation of the used software components ROS, Movebase, RTAB-Map and ALVAR is described in detail and tested in an experimental setting.\n","date":1573689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573689600,"objectID":"8fd9544697bbf18c2c748da11ce32dbf","permalink":"https://nrottmann.github.io/thesis/nicostudt/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/thesis/nicostudt/","section":"thesis","summary":"Abstract The focus of this work is on extending the functionality of the robot platform Loomo. Using cartography and navigation methods, the basis for an autonomous system is created. In addition, the recognition and storage of AR markers simplifies human-robot interaction by enabling targeted navigation to specific locations. The implementation of the used software components ROS, Movebase, RTAB-Map and ALVAR is described in detail and tested in an experimental setting.","tags":["Mobile Robotics","SLAM","Navigation","Planning"],"title":"Simultaneous Localization and Mapping with Room Labeling","type":"thesis"},{"authors":["Robin Denz"],"categories":null,"content":" Abstract The demand among the population for household robots continues to rise. These include in particular mobile cleaning and lawn mowing robots. These are usually very expensive and still very inefficient. Especially for lawn mowing robots, it is essential to have visited the entire working space in order to perform their task correctly. However, the current state of the art is still random walk algorithms, which are very unreliable and inefficient. The present bachelor thesis therefore presents a method for intelligent path planning for mobile \u0026ldquo;low cost\u0026rdquo;robots using a lawn mower robot. The robot is only equipped with binary sensors to detect its position in its working space, which is fraught with high uncertainties. By an intelligent representation of the already visited working space as well as the path planning inspired by neural networks, the lawn mower robot manages to achieve a decisive improvement in efficiency compared to the random walk.\n","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"9e96c1c2c6647c11d8aa2bd6ad00e23a","permalink":"https://nrottmann.github.io/thesis/robindenz/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/thesis/robindenz/","section":"thesis","summary":"Abstract The demand among the population for household robots continues to rise. These include in particular mobile cleaning and lawn mowing robots. These are usually very expensive and still very inefficient. Especially for lawn mowing robots, it is essential to have visited the entire working space in order to perform their task correctly. However, the current state of the art is still random walk algorithms, which are very unreliable and inefficient.","tags":["Mobile Robotics","Navigation","Planning"],"title":"Complete coverage path planning for low cost robots","type":"thesis"},{"authors":[],"categories":null,"content":"","date":1573315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573315200,"objectID":"16413d25ba162aa9320873bc02864f1a","permalink":"https://nrottmann.github.io/talk/nook2019/","publishdate":"2019-11-17T00:00:00Z","relpermalink":"/talk/nook2019/","section":"talk","summary":"Presentation of different methods for mobile robotics","tags":["Mobile Robotics","SLAM","Navigation","Localization"],"title":"MIRANA - A mobile robotic assistant","type":"talk"},{"authors":["Nils Rottmann"],"categories":[],"content":"The Lübecker Nachrichten reports about robots in everyday life: digital helpers are available at UKSH. Our MIRANA project is also part of it. Have a look whole report here.\n","date":1573221600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573221600,"objectID":"8350be4516c9323ebd3ec5d37cc9756a","permalink":"https://nrottmann.github.io/post/ln_article/","publishdate":"2019-11-08T14:00:00Z","relpermalink":"/post/ln_article/","section":"post","summary":"The Lübecker Nachrichten reports about robots in everyday life: digital helpers are available at UKSH. Our MIRANA project is also part of it.","tags":["Mobile Robotics"],"title":"Lübecker Nachrichten reports about MIRANA","type":"post"},{"authors":["Nils Rottmann"],"categories":[],"content":"The opening of the USKH in Lübeck was a nice event where we had again the opportunity to present our MIRANA robot. The opening was together with an open house day, which gave us the opportunity to directly test on how MIRANA resonates with the potential patientes.\n","date":1573221600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573221600,"objectID":"33963bda169e8154f7d599ee8bea17ba","permalink":"https://nrottmann.github.io/post/ukshopening/","publishdate":"2019-11-08T14:00:00Z","relpermalink":"/post/ukshopening/","section":"post","summary":"The Opening of the UKSH Lübeck together with a presentation of our MIRANA project.","tags":["Mobile Robotics"],"title":"UKSH Opening, Lübeck","type":"post"},{"authors":[],"categories":null,"content":"","date":1570521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570521600,"objectID":"066341bcd737f93e076d5d0a9d8da5c2","permalink":"https://nrottmann.github.io/talk/autumnschool2019/","publishdate":"2019-10-08T00:00:00Z","relpermalink":"/talk/autumnschool2019/","section":"talk","summary":"Localization and Navgation for Mobile Robotos","tags":["Mobile Robotics","SLAM","Navigation","Localization"],"title":"Autumn School","type":"talk"},{"authors":[],"categories":null,"content":"","date":1568292600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568292600,"objectID":"b571a953756df456cdcdabc67ea76a0f","permalink":"https://nrottmann.github.io/talk/hhkiel2019/","publishdate":"2019-08-29T00:00:00Z","relpermalink":"/talk/hhkiel2019/","section":"talk","summary":"An introduction to the MIRANA project","tags":["Mobile Robotics","SLAM","Navigation","Planning","Speech Recognition"],"title":"Healthcare Hackathon Kiel - MIRANA Introduction","type":"talk"},{"authors":["Nils Rottmann"],"categories":[],"content":"The European Conference on Mobile Robots 2019 in Prag finished. Three days of interesting talks about a wide variety of mobile applications and algorithms for mobile applications. If you want to have a closer look onto the given topics, feel free to visit the website.\n","date":1567800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567800000,"objectID":"b29b9ad7f322aab38ee65b52e0f53bce","permalink":"https://nrottmann.github.io/post/ecmr2019/","publishdate":"2019-09-06T20:00:00Z","relpermalink":"/post/ecmr2019/","section":"post","summary":"The European Conference on Mobile Robots 2019 in Prag finished. Three days of interesting talks about a wide variety of mobile applications.","tags":[],"title":"ECMR 2019, Prag","type":"post"},{"authors":["Nils Rottmann"],"categories":[],"content":"During the Healthcare Hackathon 2019 in Berlin (02. - 03. September), we had the opportunity to present our MIRANA project to a broad audience and to the Minister for Healthcare, Jens Spahn. The Hackathon was organized by the Universitätsklinikum Schleswig-Holstein (UKSH) und der Unimedizin Mainz (UM) together with the Federal Ministry for Healthcare. Around 20 groups attended and developed their ideas in the area of healthcare. Thereby they worked on a broad range of applications, for example smartphone applications or robotic systems. We presented the recent achievements for our MIRANA project (http://www.rob.uni-luebeck.de/mirana/).\n","date":1567800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567800000,"objectID":"c819e5ea7deb8ef1313690f0e93f6857","permalink":"https://nrottmann.github.io/post/hh19_berlin/","publishdate":"2019-09-06T20:00:00Z","relpermalink":"/post/hh19_berlin/","section":"post","summary":"During the Healthcare Hackathon 2019 in Berlin, we had the opportunity to present our MIRANA project to a broad audience.","tags":[],"title":"Healthcare Hackathon 2019 in Berlin","type":"post"},{"authors":["Nils Rottmann","Ralf Bruder","Achim Schweikard","Elmar Rueckert"],"categories":null,"content":"","date":1567641600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"e292641c7d5bf70b4a9410b8869d972c","permalink":"https://nrottmann.github.io/publication/ecmr2019/","publishdate":"2019-08-29T00:00:00Z","relpermalink":"/publication/ecmr2019/","section":"publication","summary":"Low cost robots, such as vacuum cleaners or lawn mowers employ simplistic and often random navigation policies. Although a large number of sophisticated mapping and planning approaches exist, they require additional sensors like LIDAR sensors, cameras or time of flight sensors. In this work, we propose a loop closure detection method based only on odometry data which can be generated using low-range or binary signal sensors together with simple wall following techniques. We show how to include the detected loop closing constraints into a pose graph formulation such that standard pose graph optimization techniques can be used for map estimation. We evaluate our map estimate and loop closure approach using both, simulation and a real lawn mower in complex and realistic environments. Our results demonstrate that our approach generates accurate map estimates on the basis of odometry data only. We further show that our assumption about the discriminative nature of neighboring poses in the pose graph is solid, even under large odometry noise. These improved map estimates provide the basis for smart navigation policies in low cost robots and extends their abilities to goal-directed behavior like pick and place or complete coverage path planning in realistic environments. ","tags":["Mobile Robotics","Mapping","SLAM"],"title":"Loop Closure Detection in Closed Environments","type":"publication"},{"authors":[],"categories":null,"content":"","date":1567515000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567515000,"objectID":"ae3b0406694ac569e387bf3c751c305f","permalink":"https://nrottmann.github.io/talk/hhberlin2019/","publishdate":"2019-08-29T00:00:00Z","relpermalink":"/talk/hhberlin2019/","section":"talk","summary":"Face Recognition for the MIRANA Project","tags":["Mobile Robotics","Face Detection"],"title":"Healthcare Hackathon Berlin Speech","type":"talk"},{"authors":null,"categories":null,"content":"","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565395200,"objectID":"2920231a2fec0f05560f1de9cd9c14bb","permalink":"https://nrottmann.github.io/project/legorobots/","publishdate":"2019-08-10T00:00:00Z","relpermalink":"/project/legorobots/","section":"project","summary":"A mobile robot project to inspire students to study robotics.","tags":["Mobile Robotics"],"title":"Our Common Future (expired)","type":"project"},{"authors":null,"categories":null,"content":"","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565395200,"objectID":"c2d873bc9398c1630092bf7453360bca","permalink":"https://nrottmann.github.io/tutorials/pml/","publishdate":"2019-08-10T00:00:00Z","relpermalink":"/tutorials/pml/","section":"tutorials","summary":"An introduction to probabilistic machine learning methods.","tags":["Machine Learning"],"title":"Probabilistic Machine Learning","type":"tutorials"},{"authors":null,"categories":null,"content":"","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565395200,"objectID":"3e612c502ccfc58379d635059eb80c8c","permalink":"https://nrottmann.github.io/tutorials/rosgazebo/","publishdate":"2019-08-10T00:00:00Z","relpermalink":"/tutorials/rosgazebo/","section":"tutorials","summary":"A tutorial to get started with ROS and Gazebo.","tags":["Mobile Robotics","ROS","Gazebo"],"title":"ROS-Gazebo Tutorial","type":"tutorials"},{"authors":null,"categories":null,"content":" Raspberry Pi for Mobile Robots This is a tutorial on how to set up your Raspberry Pi for controlling a mobile robot. Therefore, we will use the Robot Operating System (ROS) together with different connection possibilities (e.g. WLAN, Mobile Net, \u0026hellip;).\nA complete Image with existing ROS installation and WLAN access point can be found here. It has everything installed and configured until including the Enable SPI and UART Connection section.\nTable of Contents Install Raspberry Pi OS \nAccess the Raspberry Pi \nROS Configuration \nWLAN Configuration \nExternal WLAN Connection \nEnable SPI and UART Connection \nDefine static addresses for USB ports \nMobile Web \nROS over Mobile Web \nVideo for Linux (V4L) and ROS \nEigen3 Installation \nInstall Raspberry Pi OS  First, we install Raspberry Pi OS onto the Raspberry Pi. There are different Images available (e.g. desktop, Lite) which can be found here. We will use the Desktop version (Raspberry Pi Os (32 Bit)). The easiest way is to use the Rapsberry Pi Imager to load the image onto your SD card (e.g. 32 GB). Optional you can download the ZIP folder of your chosen Raspberry OS version and load it onto a Micro SD card with your own software, e.g. the Win32 Disk Manager (Windows), which can be found here. Therefore, unpack the downloaded ZIP folder (it contains an .img file of the OS), start the Win32 Disk Manager, choose the .img-file and the right data medium and start writing onto the SD card.\nAccess the Raspberry Pi  To access the Raspberry Pi for installing required components, we first enable the SSH connection. Therefore, we connect a monitor and a keyboard to the Raspberry Pi, start it and login with the default username and password\nusername: pi password: raspberry  To enable SSH connection, we type\nsudo raspi-config  navigate to Interfacing Options, then to P2 SSH and enable the SSH server option. Now we can connect via SSH, e.g. using Putty. Therefore, connect the Raspberry Pi to your local network via ethernet. Probably, your Raspberry Pi has to be registered by your system administrator via its MAC address to get a valid IP. Now we can proceed with the further configurations, but first you might want to change your password by typing\npasswd  ROS Configuration  To operate our mobile robot we will use the Robot Operating System (ROS). We start by updating and upgrading our system\nsudo apt update sudo apt upgrade  We now check the version of our Raspberry OS\ncat /etc/os-release  It will show something similar to\nPRETTY_NAME=\u0026quot;Raspbian GNU/Linux 10 (buster)\u0026quot; NAME=\u0026quot;Raspbian GNU/Linux\u0026quot; VERSION_ID=\u0026quot;10\u0026quot; VERSION=\u0026quot;10 (buster)\u0026quot; VERSION_CODENAME=buster ID=raspbian ID_LIKE=debian HOME_URL=\u0026quot;http://www.raspbian.org/\u0026quot; SUPPORT_URL=\u0026quot;http://www.raspbian.org/RaspbianForums\u0026quot; BUG_REPORT_URL=\u0026quot;http://www.raspbian.org/RaspbianBugs\u0026quot;  As you can see, our version is \u0026ldquo;buster\u0026rdquo;. Hence, we can install the current ROS version Melodic onto our Raspberry Pi. To do so, we will follow ROS Installation Tutorial for the Raspberry Pi. We start by installing the repository key\nsudo sh -c 'echo \u0026quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\u0026quot; \u0026gt; /etc/apt/sources.list.d/ros-latest.list' sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654  and updating the system\nsudo apt update sudo apt upgrade  Now, we install the bootstrap dependencies\nsudo apt install -y python-rosdep python-rosinstall-generator python-wstool python-rosinstall build-essential cmake  We will proceed by downloading required files and building ROS-Melodic. First, we require a catkin workspace\nmkdir -p ~/ros_catkin_ws cd ~/ros_catkin_ws  to then fetch the core packages (no GUI-tools) and build them\nrosinstall_generator ros_comm --rosdistro melodic --deps --wet-only --tar \u0026gt; melodic-ros_comm-wet.rosinstall wstool init src melodic-ros_comm-wet.rosinstall  We proceed by resolving the dependencies (that should take a while)\nrosdep install -y --from-paths src --ignore-src --rosdistro melodic -r --os=debian:buster sudo rosdep init rosdep update  Now, after downloading the packages and resolving the dependencies, we can start building ROS by invoking catkin_make_isolated. It might be required that you decrease the compilation thread with the -j1 or -j2 option\nsudo ./src/catkin/bin/catkin_make_isolated --install -DCMAKE_BUILD_TYPE=Release --install-space /opt/ros/melodic  Now source the ROS environment and also put it into the ~/.bashrc, such that it get sourced automatically for every bash session\nsource /opt/ros/melodic/setup.bash echo \u0026quot;source /opt/ros/melodic/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrc  ROS is now completely set up. If you require additional packages, follow up this procedure.\nWLAN Configuration  In order to be able to access the Raspberry Pi in absence of any local network, we let the Raspberry Pi open a WLAN by itself. We can then easily control and monitor our mobile robot over this network, e.g. by using ROS-Mobile. First, we install required software\nsudo apt install dnsmasq hostapd  Add network configuration to the default activated DHCP Client Daemon by opening the config file\nsudo nano /etc/dhcpcd.conf  and including\ninterface wlan0 static ip_address=192.168.1.1/24  by saving the changes with ctrl+o and returning with ctrl+x. As you can see, we assign our WLAN-Interface a static IP, which might be essential for the use as DHCP- or DNS-Server. Now, we restart the DHCP client daemon\nsudo systemctl restart dhcpcd  Check if both network interfaces are available with\nip l  It should appear something similar to\n1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether b8:27:eb:44:ba:d4 brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DORMANT group default qlen 1000 link/ether b8:27:eb:11:ef:81 brd ff:ff:ff:ff:ff:ff  Next, we change the configurations for the DHCP-server and the DNS-cache, which both are included in the \u0026ldquo;dnsmasq\u0026rdquo; file. We save a copy of the current file as backup and then open the file for adding our configurations\nsudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf_alt sudo nano /etc/dnsmasq.conf  We add the following lines\n# DHCP-Server active for wlan0 interface=wlan0 # DHCP-Server non-active for existing network no-dhcp-interface=eth0 # IPv4-addresses and lease time dhcp-range=192.168.1.100,192.168.1.200,255.255.255.0,24h # DNS dhcp-option=option:dns-server,192.168.1.1  Save and close again with ctrl+o and ctrl+x. Let us now test our configurations\ndnsmasq --test -C /etc/dnsmasq.conf  Hopefully, it gives back now an \u0026ldquo;OK\u0026rdquo;. Finally, we restart the dnsmasq, checking the status and enabling the autostart mode\nsudo systemctl restart dnsmasq sudo systemctl status dnsmasq sudo systemctl enable dnsmasq  By checking the status, the service should be \u0026ldquo;Active\u0026rdquo;. In the last step, we now configure the \u0026ldquo;hostapd\u0026rdquo;. Therefore, we open\nsudo nano /etc/hostapd/hostapd.conf  which should be an empty file. We add the following lines\n# Interface interface=wlan0 # WLAN-Configuration ssid=myRobotWLAN channel=1 hw_mode=g ieee80211n=1 ieee80211d=1 country_code=DE wmm_enabled=1 # WLAN-Encryption auth_algs=1 wpa=2 wpa_key_mgmt=WPA-PSK rsn_pairwise=CCMP wpa_passphrase=12345678  Our WLAN has now the name myRobotWLAN and the password is \u0026ldquo;12345678\u0026rdquo;. Since this file holds the WLAN password, we should only allow the user root to get access\nsudo chmod 600 /etc/hostapd/hostapd.conf  Lets us now check if the \u0026ldquo;hostapd\u0026rdquo; can be successfully put into operation\nsudo hostapd -dd /etc/hostapd/hostapd.conf  If successfully, it should not go back to command input and show the following two lines somewhere\nwlan0: interface state COUNTRY_UPDATE-\u0026gt;ENABLED wlan0: AP-ENABLED  If it goes back to command input or puts out error message, multiple error sources are possible. One common mistake is that you did not specify the country in which you operate, such that WLAN in general is disabled. Therefore go to\nsudo raspi-config  and enable the WLAN. To let the \u0026ldquo;hostapd\u0026rdquo; start in the background as daemon we open the default configurations\nsudo nano /etc/default/hostapd  and add\nRUN_DAEMON=yes DAEMON_CONF=\u0026quot;/etc/hostapd/hostapd.conf\u0026quot;  Finally, we take the \u0026ldquo;hostapd\u0026rdquo; in work with\nsudo systemctl unmask hostapd sudo systemctl start hostapd sudo systemctl enable hostapd  We can check if everything is successful by typing\nsudo systemctl status hostapd  where \u0026ldquo;active\u0026rdquo; and \u0026ldquo;loaded\u0026rdquo; should be stated. We can now access the WLAN \u0026ldquo;myRobotWLAN\u0026rdquo; and connect via SSH to our Raspberry Pi.\nYou can also find the presented tutorial here (it is in german).\nExternal WLAN Connection If you want the Raspberry to access an external WLAN instead of open an own one, just open\nsudo nano /etc/network/interfaces  and add the WLAN specification\n# External WLAN allow-hotplug wlan0 iface wlan0 inet manual wpa-ssid \u0026quot;WLAN-NAME\u0026quot; wpa-psk \u0026quot;WLAN-PASSWORT\u0026quot;  Afterwards, restart the interface\nsudo ifdown wlan0 sudo ifup wlan0  Enable SPI and UART Connection  Some sensors might require UART or SPI connections. To enable those connections we can change the boot config file\nsudo nano /boot/config.txt  and add the following lines\n# This enables devices 0.0 and 0.1 dtparam=spi=on dtoverlay=spi1-3cs,cs0_pin=16,cs1_pin=12,cs2_pin=6 # Enable UART enable_uart=1  In addition, we have to enable serial devices in general by going into the configuration setup\nsudo raspi-config  Go to interfacing options and enable serial connections.\nDefine static addresses for USB ports  You might like to have static addresses for your USB ports, such that you can easily access them within your ROS nodes. To define these static addresses, we add a new file to the udev rules\nsudo nano /etc/udev/rules.d/99-usb-serial.rules  and add there the following lines\nSUBSYSTEM==\u0026quot;tty\u0026quot;, KERNELS==\u0026quot;1-1.2\u0026quot;, SYMLINK+=\u0026quot;sensor01\u0026quot; SUBSYSTEM==\u0026quot;tty\u0026quot;, KERNELS==\u0026quot;1-1.3\u0026quot;, SYMLINK+=\u0026quot;sensor02\u0026quot; SUBSYSTEM==\u0026quot;tty\u0026quot;, KERNELS==\u0026quot;1-1.4\u0026quot;, SYMLINK+=\u0026quot;sensor03\u0026quot; SUBSYSTEM==\u0026quot;tty\u0026quot;, KERNELS==\u0026quot;1-1.5\u0026quot;, SYMLINK+=\u0026quot;sensor04\u0026quot;  That defines for the 4 USB ports of the Raspberry Pi the static addresses sensor01, \u0026hellip;, sensor04. Be sure that the correct quotes for the strings have been used. Below you can see the defined port declaration.\nThe KERNELS might differ in your case, dependent on your hardware settings. To find out your KERNELS for the individual USB ports, plug a USB device into each port (one by one) and check\nudevadm info -a -p $(udevadm info -q path -n /dev/ttyACM0)  Your will receive the current serial connection information and will find something like\n... looking at parent device '/devices/pci0000:00/0000:00:14.0/usb1/1-3/1-3:1.3': KERNELS==\u0026quot;1-3:1.3\u0026quot; ...  where everything before the colon, thus \u0026ldquo;1-3\u0026rdquo;, would be your entry for the KERNELS in the udev rules. To apply the new rules we have to reload them with the udevadm manager as super user\nsudo su sudo udevadm control --reload-rules \u0026amp;\u0026amp; udevadm trigger exit  You can check a serial port by connecting a device and try to read from it, e.g.\ncat /dev/sensor01  Mobile Web  To allow the Raspberry Pi to connect to the Mobile Web, we can use the Raspberry Pi 3G/4G \u0026amp; LTE Base HAT together with a prepaid mobile SIMcard (e.g. Aldi Talk). Follow up this tutorial to get started. You require your APN, which would be for Aldi Talk\ninternet.eplus.de  You can test your internet connection by installing\nsudo apt install dnsutils  and using \u0026ldquo;nslookup\u0026rdquo;\nnslookup google.de  ROS over Mobile Web  To allow ROS connections via the Mobile Web, we require a secure VPN network with one server and multiple clients. The computer on which the server is running should have a static IP address for the internet connection. We assume that the VPN server is hosted on a computer running Linux Ubuntu 18.04. We start by installing OpenVPN and easy-rsa\nsudo apt install openvpn sudo apt install easy-rsa  Easy-rsa is needed for generating all keys and certificates we require. Therefore, we copy the folder for the key generation to a suitable place\nsudo cp -r /usr/share/easy-rsa /etc/openvpn/easy-rsa2  We now have to adapt the file \u0026ldquo;vars\u0026rdquo; in the easy-rsa2 folder\ncd easy-rsa2 sudo nano vars  Here we have to change the following entries that they fit to out situation\nexport KEY_COUNTRY=\u0026quot;DE\u0026quot; export KEY_PROVINCE=\u0026quot;Schleswig-Holstein\u0026quot; export KEY_CITY=\u0026quot;Luebeck\u0026quot; export KEY_ORG=\u0026quot;ROB\u0026quot; export KEY_EMAIL=\u0026quot;info@webmaster\u0026quot; export KEY_EMAIL=info@webmaster export KEY_CN=changeme export KEY_NAME=changeme export KEY_OU=changeme export PKCS11_MODULE_PATH=changeme export PKCS11_PIN=1234  Also we have to add the line\nexport KEY_ALTNAMES=\u0026quot;Irgendwas\u0026quot;  We check now if the folder \u0026ldquo;keys\u0026rdquo; already exists, if not, we add it\nsudo mkdir keys  Next, we change the name of the latest \u0026ldquo;openssl-x.x.x.cnf\u0026rdquo; to \u0026ldquo;openssl.cnf\u0026rdquo;\nsudo cp openssl-x.x.x.cnf openssl.cnf  The above adapted file \u0026ldquo;vars\u0026rdquo; has to be now sourced\nsource ./vars  There will be a warning. Now we can generate the master certificate and key\nsudo -E ./clean-all sudo -E ./build-ca  the \u0026ldquo;dh2048.pem\u0026rdquo; file\nsudo -E ./build-dh  and the certificate and key for the server\nsudo -E ./build-key-server server  Now we can generate the keys and certificates for the different clients\nsudo -E ./build-key client1 sudo -E ./build-key client2 sudo -E ./build-key client3  Finally, we require to generate the Diffie-Hellmann-Parameter\nsudo -E ./build-dh  For the client we need only the .key, the .crt and the ca.crt files. We can pack them and send them to our clients\ntar -cf client1.tar client1.key client1.crt ca.crt  We now need to define a configuration file for the server, \u0026ldquo;server.conf\u0026rdquo;, with\ncd /etc/openvpn sudo nano server.conf  Add into this file the following lines\ndev tun proto udp port 1194 ca /etc/openvpn/easy-rsa2/keys/ca.crt cert /etc/openvpn/easy-rsa2/keys/server.crt key /etc/openvpn/easy-rsa2/keys/server.key # This file should be kept secret dh /etc/openvpn/easy-rsa2/keys/dh2048.pem topology subnet server 10.8.0.0 255.255.255.0 client-config-dir ccd client-to-client keepalive 1 10 cipher AES-256-CBC # AES comp-lzo no persist-key persist-tun status openvpn-status.log verb 4  We add also a directory \u0026ldquo;ccd\u0026rdquo; (client-config-directory) and add client files to define static IP addresses for each client\nsudo mkdir ccd cd ccd sudo nano client1  where we add the following line\nifconfig-push 10.8.0.2 255.255.255.0  Here, the IP is the static IP attached to the client. Now we can run our server using\nsudo openvpn server.conf  Cellphone as Client (Android) We first generate a file named \u0026ldquo;client.ovpn\u0026rdquo;\ncd ~ nano client.ovpn  and add the following lines\nclient proto udp dev tun remote server.ip 1194 resolv-retry infinite persist-key persist-tun ca ca.crt cert client1.crt key client1.key remote-cert-tls server cipher AES-256-CBC comp-lzo no verb 3  where we insert the correct static server IP. We then copy this file together with the \u0026ldquo;client1.key\u0026rdquo;, \u0026ldquo;client1.crt\u0026rdquo;, \u0026ldquo;ca.crt\u0026rdquo; files to a chosen folder on our mobile phone. Then, download the \u0026ldquo;OpenVPN Connect\u0026rdquo; App and find the \u0026ldquo;client.ovpn\u0026rdquo; file. Now you can simply press the connect button and the connection to your server (if the server is running) should be established.\nRaspberry Pi as Client Install openvpn\nsudo apt install openvpn  Generate a file called \u0026ldquo;client.conf\u0026rdquo;\ncd /etc/openvpn sudo nano client.conf  and add the following lines\nclient proto udp dev tun remote server.ip 1194 resolv-retry infinite persist-key persist-tun ca ca.crt cert client1.crt key client1.key remote-cert-tls server cipher AES-256-CBC comp-lzo no verb 3  where we insert the correct static server IP. Put the \u0026ldquo;client1.key\u0026rdquo;, \u0026ldquo;client1.crt\u0026rdquo;, \u0026ldquo;ca.crt\u0026rdquo; files into the \u0026ldquo;/etc/openvpn\u0026rdquo; folder. You can start now the connection using\nsudo openvpn client.conf  Test the System In order to check if our system works for sending ROS messages, we can use a simple talker node. Therefore, download the sample code onto one of your clients which consist of a ROS package, which should be placed into the \u0026ldquo;src\u0026rdquo; folder of a catkin workspace. Thus, we first create such a workspace and \u0026ldquo;src\u0026rdquo; folder\ncd ~ sudo mkdir -p catkin_ws/src  Now put the \u0026ldquo;connection_test\u0026rdquo; package into this folder and compile\ncd ~/catkin_ws catkin_make  The accompanied bash script will set all required environmental variables and start our test launch file. Therefore, put this into your home folder, make it executable and start it. But before, adjust the IP according to your system, (e.g. for client1 it might be the 10.8.0.2, depending which static IPs you assigned)\n./startConnection.sh  Now, we can try to listen to the chatter topic from a different client or from the server. Be aware, that you also have to set the correct IP address onto these system.\nVideo for Linux (V4L) and ROS Let\u0026rsquo;s assume you have a V4L compatible camera which you can simply plug in to one of the USB ports of the Raspberry Pi. You can check whether the camera is correctly recognized by typing\nls /dev/video*  You should get some video devices as return, e.g. /dev/video0 or /dev/video1. The different devices stand for different output formats of the connected camera, e.g. MJPG or H.264. In order to check this as well as supported framerates and framesizes, type\nv4l2-ctl --device=0 --list-formats-ext  Streaming via VLC We can now feed forward the video stream via a VLC server installing first VLC\nsudo apt-get install vlc  and then using\ncvlc -vvv v4l2:///dev/video0 --sout '#rtp{sdp=rtsp://:8554/}' :demux=h264  To get access to the stream, we can now open the VLC media player on any other device connected to the same network as the Raspberry Pi, open the Tab \u0026ldquo;media\u0026rdquo;, open \u0026ldquo;open network stream\u0026rdquo; and insert\nrtsp://141.83.19.37:8554/  Video to ROS In order to feed forward video data to the ROS system, we can use \u0026ldquo;usb_cam\u0026rdquo; together with \u0026ldquo;compressed_image_transport\u0026rdquo;. Unfortunately, ROS currently does not support the H.264 format such that we have to use the MJPG compression format. Start now by installing the required nodes following up this procedure\ncd ~/ros_catkin_ws rosinstall_generator usb_cam compressed_image_transport --rosdistro melodic --deps --wet-only --tar \u0026gt; melodic-custom_ros.rosinstall wstool merge -t src melodic-custom_ros.rosinstall wstool update -t src rosdep install --from-paths src --ignore-src --rosdistro melodic -y -r --os=debian:buster sudo ./src/catkin/bin/catkin_make_isolated --install -DCMAKE_BUILD_TYPE=Release --install-space /opt/ros/melodic -j1  After installing everything, we can then create a launch file\n\u0026lt;launch\u0026gt; \u0026lt;node name=\u0026quot;usb_cam\u0026quot; pkg=\u0026quot;usb_cam\u0026quot; type=\u0026quot;usb_cam_node\u0026quot; output=\u0026quot;screen\u0026quot; \u0026gt; \u0026lt;param name=\u0026quot;video_device\u0026quot; value=\u0026quot;/dev/video0\u0026quot; /\u0026gt; \u0026lt;param name=\u0026quot;image_width\u0026quot; value=\u0026quot;640\u0026quot; /\u0026gt; \u0026lt;param name=\u0026quot;image_height\u0026quot; value=\u0026quot;480\u0026quot; /\u0026gt; \u0026lt;param name=\u0026quot;pixel_format\u0026quot; value=\u0026quot;yuyv\u0026quot; /\u0026gt; \u0026lt;param name=\u0026quot;camera_frame_id\u0026quot; value=\u0026quot;usb_cam\u0026quot; /\u0026gt; \u0026lt;param name=\u0026quot;io_method\u0026quot; value=\u0026quot;mmap\u0026quot;/\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/launch\u0026gt;  filling up the correct parameters which can be detected with above mentioned \u0026ldquo;cvlc\u0026rdquo;.\nEigen3 Installation  Your might want to use Eigen3 as math library for some ROS nodes (e.g. a Kalman Filter). To install the Eigen3 package \u0026hellip;\n","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565395200,"objectID":"94fb2b8119251402bb4fe3bb5deb92ab","permalink":"https://nrottmann.github.io/tutorials/raspberrypi/","publishdate":"2019-08-10T00:00:00Z","relpermalink":"/tutorials/raspberrypi/","section":"tutorials","summary":"This is a tutorial on how to set up your Raspberry Pi for controlling a mobile robot via ROS.","tags":["Mobile Robotics","ROS"],"title":"Raspberry Pi Configuration","type":"tutorials"},{"authors":null,"categories":null,"content":"","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565395200,"objectID":"437b37cd7a05aa42c3409a4b62b8e9e1","permalink":"https://nrottmann.github.io/project/train/","publishdate":"2019-08-10T00:00:00Z","relpermalink":"/project/train/","section":"project","summary":"Active transfer learning with neural networks through human-robot interactions.","tags":["Reinforcement Learning"],"title":"TRAIN (expired)","type":"project"},{"authors":null,"categories":null,"content":"","date":1565136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565136000,"objectID":"5fc857832f6ea5a2d8c50ce882665fa8","permalink":"https://nrottmann.github.io/project/mirana/","publishdate":"2019-08-07T00:00:00Z","relpermalink":"/project/mirana/","section":"project","summary":"A Mobile Intelligent Robotic Assistant for Navigation and Assistance.","tags":["Mobile Robotics"],"title":"MIRANA (expired)","type":"project"},{"authors":["Alexander Walter"],"categories":null,"content":" Abstract Based on the intention to build an autonomous lawn mower robot, this work examines the viability of a sensor and microprocessor for onboard plant clas- sification using machine learning. Usually, some sort of fencing is required to keep the robot in its intended processing area, so such a sensor would allow the robot to differentiate between grass and e.g. flowers. Also, the drive and blade speed can be adjusted for certain species or plant densities, etc. For this, a data set was collected utilizing a specific method called chloro- phyll fluorescence induction. A series of narrowband LEDs are used to drive this process, while a spectrometer measures the spectral intensity. The plant will fluoresce in specific wavelengths when sufficiantly illuminated. With this data, machine learning algorithms are trained to explore if they are capable to classify these plants without further information. With accuracies up to 98% for three plants commonly present on a lawn and up to 86% for eight plants, the results show that chlorophyll fluorescence is a viable method for classification, even under sunlight using the random forest machine learning algorithm.\n","date":1560729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560729600,"objectID":"70cf3948831212a0bb89ce9ca6a2ceca","permalink":"https://nrottmann.github.io/thesis/alexanderwalter/","publishdate":"2019-06-17T00:00:00Z","relpermalink":"/thesis/alexanderwalter/","section":"thesis","summary":"Abstract Based on the intention to build an autonomous lawn mower robot, this work examines the viability of a sensor and microprocessor for onboard plant clas- sification using machine learning. Usually, some sort of fencing is required to keep the robot in its intended processing area, so such a sensor would allow the robot to differentiate between grass and e.g. flowers. Also, the drive and blade speed can be adjusted for certain species or plant densities, etc.","tags":["Sensors","Optimization","Machine Learning"],"title":"Machine Learning for plant classification based on chlorophyll detection","type":"thesis"},{"authors":[],"categories":null,"content":"","date":1552395000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552395000,"objectID":"cd3b29dc0b0c3d4b4dac4ba970853bde","permalink":"https://nrottmann.github.io/talk/thinkatibm2019/","publishdate":"2019-08-29T00:00:00Z","relpermalink":"/talk/thinkatibm2019/","section":"talk","summary":"An introduction to the MIRANA project","tags":["Mobile Robotics","SLAM","Navigation","Planning","Speech Recognition"],"title":"Think at IBM","type":"talk"},{"authors":["Nils Rottmann","Ralf Bruder","Achim Schweikard","Elmar Rueckert"],"categories":null,"content":"","date":1550707200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550707200,"objectID":"5370f88413ebfd71e4e0756357384011","permalink":"https://nrottmann.github.io/publication/biosignals2019/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/publication/biosignals2019/","section":"publication","summary":"Low cost robots, such as vacuum cleaners or lawn mowers, employ simplistic and often random navigation policies. Although a large number of sophisticated localization and planning approaches exist, they require additional sensors like LIDAR sensors, cameras or time of flight sensors. In this work, we propose a global localization method biologically inspired by simple insects, such as the ant Cataglyphis that is able to return from distant locations to its nest in the desert without any or with limited perceptual cues. Like in Cataglyphis, the underlying idea of our localization approach is to first compute a pose estimate from pro-prioceptual sensors only, using land navigation, and thereafter refine the estimate through a systematic search in a particle filter that integrates the rare visual feedback. In simulation experiments in multiple environments, we demonstrated that this bioinspired principle can be used to compute accurate pose estimates from binary visual cues only. Such intelligent localization strategies can improve the performance of any robot with limited sensing capabilities such as household robots or toys.","tags":["Mobile Robotics","Localization"],"title":"Cataglyphis ant navigation strategies solve the global localization problem in robots with binary sensors","type":"publication"},{"authors":["Alexander Osiik"],"categories":null,"content":" Abstract This Bachelor thesis presents an approach for the complete coverage path planning (CCPP) problem which occurs for different robotic applications, such as autonomous lawn mowers or vaccuum cleaners. Methods used for localization [27], map representation [10] and planning [14] are discussed under consideration of sensor noise and uncertainty about the own position induced by the movement of the robot. An efficient method to solve the CCPP problem under uncertainty is proposed and evaluated due to simulations. The results show that under simulated conditions, the autonomous lawnmower covers the field of work faster and can guarantee complete coverage, in contrast to commercially used techniques. Furthermore, an efficient algorithm to divide the working area into smaller areas is developed, which leads to an increased computational and storage efficiency.\n","date":1542326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542326400,"objectID":"bce50d9dd7eec59dbbf29c3e224b1568","permalink":"https://nrottmann.github.io/thesis/alexanderosiik/","publishdate":"2018-11-16T00:00:00Z","relpermalink":"/thesis/alexanderosiik/","section":"thesis","summary":"Abstract This Bachelor thesis presents an approach for the complete coverage path planning (CCPP) problem which occurs for different robotic applications, such as autonomous lawn mowers or vaccuum cleaners. Methods used for localization [27], map representation [10] and planning [14] are discussed under consideration of sensor noise and uncertainty about the own position induced by the movement of the robot. An efficient method to solve the CCPP problem under uncertainty is proposed and evaluated due to simulations.","tags":["Mobile Robotics","planning","Navigation"],"title":"Trajectory planning for mobile robots for working area complete coverage under high uncertainty","type":"thesis"},{"authors":["Glenn Roewekamp"],"categories":null,"content":" Abstract Medical interventions are often supported by imaging and position-determining procedures. In this thesis we investigate to what extent electromagnetic tracking systems can be used for accurate positioning. The focus is first on 2D, then on 3D systems.\n","date":1541894400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541894400,"objectID":"10acea633e79918965a50f2bfdbebd4e","permalink":"https://nrottmann.github.io/thesis/glennroewekamp/","publishdate":"2018-09-14T00:00:00Z","relpermalink":"/thesis/glennroewekamp/","section":"thesis","summary":"Abstract Medical interventions are often supported by imaging and position-determining procedures. In this thesis we investigate to what extent electromagnetic tracking systems can be used for accurate positioning. The focus is first on 2D, then on 3D systems.","tags":["Sensors","Medical Devices","Localization"],"title":"Development of an electromagnetic Tracking System for use in Medical Interventions","type":"thesis"},{"authors":["Friedrich Podstawa"],"categories":null,"content":" Abstract To make it easier for people to work in the lawn care, there is a long list of robotic lawnmowers. The navigation is a big problem, since the application is usually limited by a perimeter wire. This process means a time as well as financial expense and must be changed. For this purpose, a new method for lawn detection was developed at the Institute of Robotics and Cognitive Systems. A hardware that measures a parameter characteristic of turf plants by optically stimulating chlorophyll synthesis and measuring the resulting chlorophyll fluorescence, and safely distinguishes turf plants from non-organic material has been designed. In this thesis, this sensor system will be further developed into a product-related prototype. The mowing area detection is significantly improved by optimizing the sensor under different lighting conditions. Furthermore, the functionality of an existing robotic lawnmower system, which will be equipped with the new sensor system, will be retained. This should reliably be able to drive over a lawn without leaving it. Tests show that the mowing area detection was significantly improved with the help of the chlorophyll fluorescence sensor. The sensor is thus suitable for outdoor use. Sensor hardware and software have been transferred from a field-less system to a perfectly functioning mower surface detection sensor.\n","date":1538870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538870400,"objectID":"40e62957015fc5e76eae59af58475071","permalink":"https://nrottmann.github.io/thesis/friedrichpodstawa/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/thesis/friedrichpodstawa/","section":"thesis","summary":"Abstract To make it easier for people to work in the lawn care, there is a long list of robotic lawnmowers. The navigation is a big problem, since the application is usually limited by a perimeter wire. This process means a time as well as financial expense and must be changed. For this purpose, a new method for lawn detection was developed at the Institute of Robotics and Cognitive Systems.","tags":["Mobile Robotics","SLAM"],"title":"Optimization of a chlorophyll-sensor for mowing-area-detection for autonomous lawn mowers","type":"thesis"},{"authors":["Rico Klinckenberg"],"categories":null,"content":" Abstract The present bachelor thesis presents the necessary methods for an exact selflocalization by using an Inertial Mesurment Unit (IMU) and the odometry of an autonomous lawn mower. This self-localization shall be used in later work together with a localization of a particle filter. The required standard models [12] for the individual sensor systems were examined and the required parameters determined. Measurements were taken with the autonomous lawn mower to develop a Kalman filter [15] based on the data obtained. With the help of the Kalman filter and a controller which was designed in this thesis, such a self-localization could be realized. The results show that the autonomous lawnmower can locate itself under simulated conditions with a higher accuracy than with a pure localization via odometry. However, final measurements show that disturbances of the IMU occur within the autonomous lawn mower, so that a final overall behaviour cannot be implemented with the current architecture of the autonomous lawn mower.\n","date":1537833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537833600,"objectID":"7c780367bfa7dbab307fd12acffed180","permalink":"https://nrottmann.github.io/thesis/ricoklinckenberg/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/thesis/ricoklinckenberg/","section":"thesis","summary":"Abstract The present bachelor thesis presents the necessary methods for an exact selflocalization by using an Inertial Mesurment Unit (IMU) and the odometry of an autonomous lawn mower. This self-localization shall be used in later work together with a localization of a particle filter. The required standard models [12] for the individual sensor systems were examined and the required parameters determined. Measurements were taken with the autonomous lawn mower to develop a Kalman filter [15] based on the data obtained.","tags":["Mobile Robotics","Navigation","Modelling"],"title":"Localizsation and Control for Trajectory Tracking for Autonomous Lawn Mowers","type":"thesis"},{"authors":["Sven Andresen"],"categories":null,"content":" Abstract Low cost robots, such as vacuum cleaners or lawn mowers employ simplistic and often random navigation policies. Although a large number of sophisticated mapping and planning approaches exist, they require additional sensors like LIDAR sensors, cameras or time of flight sensors. In this work, we investigate SLAM techniques for efficient mapping and localization with limited sensing capabilities.\n","date":1537660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537660800,"objectID":"5de1e43b0b6b8863f55527555c97ee5f","permalink":"https://nrottmann.github.io/thesis/svenandresen/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/thesis/svenandresen/","section":"thesis","summary":"Abstract Low cost robots, such as vacuum cleaners or lawn mowers employ simplistic and often random navigation policies. Although a large number of sophisticated mapping and planning approaches exist, they require additional sensors like LIDAR sensors, cameras or time of flight sensors. In this work, we investigate SLAM techniques for efficient mapping and localization with limited sensing capabilities.","tags":["Mobile Robotics","SLAM"],"title":"Simultaneous Localization and Mapping for Autonomous Lawn Mowers","type":"thesis"}]