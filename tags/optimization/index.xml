<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Optimization | Nils Rottmann | Homepage</title>
    <link>https://nrottmann.github.io/tags/optimization/</link>
      <atom:link href="https://nrottmann.github.io/tags/optimization/index.xml" rel="self" type="application/rss+xml" />
    <description>Optimization</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 25 Oct 2020 08:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nrottmann.github.io/img/icon-192.png</url>
      <title>Optimization</title>
      <link>https://nrottmann.github.io/tags/optimization/</link>
    </image>
    
    <item>
      <title>Exploiting Chlorophyll Fluorescense for building robust low-cost Mowing Area Detectors</title>
      <link>https://nrottmann.github.io/talk/sensors2020/</link>
      <pubDate>Sun, 25 Oct 2020 08:00:00 +0000</pubDate>
      <guid>https://nrottmann.github.io/talk/sensors2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning Hierarchical Acquisition Functions for Bayesian Optimization</title>
      <link>https://nrottmann.github.io/talk/iros2020/</link>
      <pubDate>Sun, 25 Oct 2020 08:00:00 +0000</pubDate>
      <guid>https://nrottmann.github.io/talk/iros2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Parameter Optimization for Loop Closure Detection in Closed Environments</title>
      <link>https://nrottmann.github.io/talk/irosws2020/</link>
      <pubDate>Sun, 25 Oct 2020 08:00:00 +0000</pubDate>
      <guid>https://nrottmann.github.io/talk/irosws2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning Hierarchical Acquisition Functions for Bayesian Optimization</title>
      <link>https://nrottmann.github.io/publication/iros2020/</link>
      <pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://nrottmann.github.io/publication/iros2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Parameter Optimization for Loop Closure Detection in Closed Environments</title>
      <link>https://nrottmann.github.io/publication/iros2020ws/</link>
      <pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://nrottmann.github.io/publication/iros2020ws/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sample-Efficient Covariance Matrix Adaptation Evolutional Strategy via Simulated Rollouts in Neural Networks</title>
      <link>https://nrottmann.github.io/publication/aspai2020/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://nrottmann.github.io/publication/aspai2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HIBO: Hierarchical Acquisition Functions for Bayesian Optimization</title>
      <link>https://nrottmann.github.io/thesis/michaelwerner/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://nrottmann.github.io/thesis/michaelwerner/</guid>
      <description>

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Bayesian Optimization is a powerful method to optimize black-box derivative-free functions, with high evaluation costs. For instance, applications can be found in the context of robotics, animation design or molecular design. However, Bayesian Optimization is not able to scale into higher dimensions, equivalent to optimizing more than 20 parameters. This thesis introduces HIBO, a new hierarchical algorithm in the context of high dimensional Bayesian Optimization. The algorithm uses an automatic feature generation. The features are used to condition the parameters, to enable faster optimization. The performance of HIBO is compared to existing high dimensional extensions of Bayesian Optimization on three common benchmark functions. Additionally, an air hockey simulation is used to examine the capability in a task-oriented setting. The conducted experiments show that HIBO performs similar to the basic Bayesian Optimization algorithm, independent from the dimensionality of the given problem. Hence, the proposed HIBO algorithm does not scale Bayesian Optimization to higher dimensions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
